{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><span style=\"color: #6495ED;\">Delhi Air Quality Forecasting</span></h1>\n",
    "<h2><span style=\"color: #6495ED;\">Deep Learning for Time Series: LSTM Networks</span></h2>\n",
    "\n",
    "Prepared by Lipsita Tripathy\n",
    "\n",
    "January 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Welcome to the series of Jupyter Notebooks dedicated to our project on \"Delhi Air Quality Prediction.\" This comprehensive project aims to develop a robust predictive model for forecasting the air quality index (AQI) in Delhi, a city known for its challenging air pollution levels. Through these notebooks, we will journey through the various stages of the project, encompassing data preparation, exploratory data analysis (EDA), baseline and advanced modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "For this project, we're using air quality data gathered from 40 stations across Delhi, covering the period from 2013 to 2023. The dataset includes 12 distinct features, each representing different air quality and environmental parameters. These data points are collected from each station and then aggregated to form a comprehensive dataset with unique datetime records for each entry.\n",
    "\n",
    "| Features                  | Description                                                | Type       |\n",
    "|---------------------------|------------------------------------------------------------|------------|\n",
    "| Datetime                  | Timestamp indicating the date and time of the recorded data | datetime64 |\n",
    "| StationId                 | Unique identifier for each monitoring station              | Numeric    |\n",
    "| PM2.5 (ug/m3)             | Particulate Matter with a diameter of 2.5 microns or less   | Numeric    |\n",
    "| PM10 (ug/m3)              | Particulate Matter with a diameter of 10 microns or less   | Numeric    |\n",
    "| NO (ug/m3)                | Nitric Oxide concentration                                 | Numeric    |\n",
    "| NO2 (ug/m3)               | Nitrogen Dioxide concentration                              | Numeric    |\n",
    "| NOx (ug/m3)               | Sum of Nitric Oxide and Nitrogen Dioxide concentrations    | Numeric    |\n",
    "| NH3 (ug/m3)               | Ammonia concentration                                      | Numeric    |\n",
    "| SO2 (ug/m3)               | Sulfur Dioxide concentration                               | Numeric    |\n",
    "| CO (ug/m3)                | Carbon Monoxide concentration                              | Numeric    |\n",
    "| Ozone (ug/m3)             | Ozone concentration                                        | Numeric    |\n",
    "| Benzene (ug/m3)           | Concentration of Benzene in the air                         | Numeric    |\n",
    "| Toluene (ug/m3)           | Concentration of Toluene in the air                         | Numeric    |\n",
    "| Xylene (ug/m3)            | Concentration of Xylene in the air                          | Numeric    |\n",
    "| RH (%)                    | Relative Humidity in percentage                            | Numeric    |\n",
    "| WS (m/s)                  | Wind Speed in meters per second                             | Numeric    |\n",
    "| WD (degree)               | Wind Direction in degrees                                  | Numeric    |\n",
    "| BP (mmHg)                 | Barometric Pressure in millimeters of mercury              | Numeric    |\n",
    "| AT (degree C)             | Ambient Temperature in degrees Celsius                     | Numeric    |\n",
    "| RF (mm)                   | Rainfall in millimeters                                    | Numeric    |\n",
    "| SR (W/mt2)                | Solar Radiation in Watts per square meter                   | Numeric    |\n",
    "\n",
    "\n",
    "| Target                    | Description                                                | Type       |\n",
    "|---------------------------|------------------------------------------------------------|------------|\n",
    "| <span style=\"color: #FF0000;\">y_AQI</span> | Target variable representing the predicted Air Quality Index for the next 24 hours | Numeric    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>AQI</th>\n",
       "      <th>PM2.5 (ug/m3)</th>\n",
       "      <th>PM10 (ug/m3)</th>\n",
       "      <th>NO (ug/m3)</th>\n",
       "      <th>NO2 (ug/m3)</th>\n",
       "      <th>NOx (ug/m3)</th>\n",
       "      <th>NH3 (ug/m3)</th>\n",
       "      <th>SO2 (ug/m3)</th>\n",
       "      <th>CO (ug/m3)</th>\n",
       "      <th>...</th>\n",
       "      <th>t_CO (ug/m3)</th>\n",
       "      <th>t_Ozone (ug/m3)</th>\n",
       "      <th>t_Benzene (ug/m3)</th>\n",
       "      <th>t_Toluene (ug/m3)</th>\n",
       "      <th>t_Xylene (ug/m3)</th>\n",
       "      <th>t_WS (m/s)</th>\n",
       "      <th>t_SR (W/mt2)</th>\n",
       "      <th>t_Volatility_Last_24hr</th>\n",
       "      <th>t_Volatility_Last_7d</th>\n",
       "      <th>t_Volatility_Last_30d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>354.0</td>\n",
       "      <td>290.774583</td>\n",
       "      <td>292.631667</td>\n",
       "      <td>52.055615</td>\n",
       "      <td>66.014148</td>\n",
       "      <td>117.224563</td>\n",
       "      <td>75.685556</td>\n",
       "      <td>9.992130</td>\n",
       "      <td>9.138167</td>\n",
       "      <td>...</td>\n",
       "      <td>2.316307</td>\n",
       "      <td>2.694264</td>\n",
       "      <td>1.844071</td>\n",
       "      <td>3.437065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314162</td>\n",
       "      <td>3.714195</td>\n",
       "      <td>2.230820</td>\n",
       "      <td>4.097861</td>\n",
       "      <td>7.233227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 01:00:00</td>\n",
       "      <td>358.0</td>\n",
       "      <td>275.749821</td>\n",
       "      <td>296.150000</td>\n",
       "      <td>37.736250</td>\n",
       "      <td>59.415630</td>\n",
       "      <td>88.122976</td>\n",
       "      <td>66.740556</td>\n",
       "      <td>9.477546</td>\n",
       "      <td>7.665310</td>\n",
       "      <td>...</td>\n",
       "      <td>2.159328</td>\n",
       "      <td>2.395890</td>\n",
       "      <td>1.851948</td>\n",
       "      <td>3.244656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330103</td>\n",
       "      <td>3.673794</td>\n",
       "      <td>2.353812</td>\n",
       "      <td>4.086369</td>\n",
       "      <td>7.233005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 02:00:00</td>\n",
       "      <td>362.0</td>\n",
       "      <td>271.463472</td>\n",
       "      <td>309.030000</td>\n",
       "      <td>26.387774</td>\n",
       "      <td>57.951291</td>\n",
       "      <td>61.464690</td>\n",
       "      <td>57.030556</td>\n",
       "      <td>9.207963</td>\n",
       "      <td>10.777421</td>\n",
       "      <td>...</td>\n",
       "      <td>2.466184</td>\n",
       "      <td>2.118250</td>\n",
       "      <td>1.835493</td>\n",
       "      <td>3.169191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329304</td>\n",
       "      <td>3.455326</td>\n",
       "      <td>2.475083</td>\n",
       "      <td>4.074597</td>\n",
       "      <td>7.232991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01 03:00:00</td>\n",
       "      <td>367.0</td>\n",
       "      <td>279.071667</td>\n",
       "      <td>317.826667</td>\n",
       "      <td>23.310857</td>\n",
       "      <td>59.172513</td>\n",
       "      <td>47.583524</td>\n",
       "      <td>43.298333</td>\n",
       "      <td>10.871667</td>\n",
       "      <td>11.793810</td>\n",
       "      <td>...</td>\n",
       "      <td>2.548961</td>\n",
       "      <td>2.187191</td>\n",
       "      <td>1.835670</td>\n",
       "      <td>3.162700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326422</td>\n",
       "      <td>3.079282</td>\n",
       "      <td>2.592957</td>\n",
       "      <td>4.063127</td>\n",
       "      <td>7.233170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01 04:00:00</td>\n",
       "      <td>370.0</td>\n",
       "      <td>269.118333</td>\n",
       "      <td>308.521667</td>\n",
       "      <td>24.574667</td>\n",
       "      <td>62.451032</td>\n",
       "      <td>43.535333</td>\n",
       "      <td>32.023333</td>\n",
       "      <td>11.020833</td>\n",
       "      <td>10.027778</td>\n",
       "      <td>...</td>\n",
       "      <td>2.400417</td>\n",
       "      <td>2.336875</td>\n",
       "      <td>1.747604</td>\n",
       "      <td>3.113589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379197</td>\n",
       "      <td>2.525195</td>\n",
       "      <td>2.692013</td>\n",
       "      <td>4.051925</td>\n",
       "      <td>7.233493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime    AQI  PM2.5 (ug/m3)  PM10 (ug/m3)  NO (ug/m3)  \\\n",
       "0  2013-01-01 00:00:00  354.0     290.774583    292.631667   52.055615   \n",
       "1  2013-01-01 01:00:00  358.0     275.749821    296.150000   37.736250   \n",
       "2  2013-01-01 02:00:00  362.0     271.463472    309.030000   26.387774   \n",
       "3  2013-01-01 03:00:00  367.0     279.071667    317.826667   23.310857   \n",
       "4  2013-01-01 04:00:00  370.0     269.118333    308.521667   24.574667   \n",
       "\n",
       "   NO2 (ug/m3)  NOx (ug/m3)  NH3 (ug/m3)  SO2 (ug/m3)  CO (ug/m3)  ...  \\\n",
       "0    66.014148   117.224563    75.685556     9.992130    9.138167  ...   \n",
       "1    59.415630    88.122976    66.740556     9.477546    7.665310  ...   \n",
       "2    57.951291    61.464690    57.030556     9.207963   10.777421  ...   \n",
       "3    59.172513    47.583524    43.298333    10.871667   11.793810  ...   \n",
       "4    62.451032    43.535333    32.023333    11.020833   10.027778  ...   \n",
       "\n",
       "   t_CO (ug/m3)  t_Ozone (ug/m3)  t_Benzene (ug/m3)  t_Toluene (ug/m3)  \\\n",
       "0      2.316307         2.694264           1.844071           3.437065   \n",
       "1      2.159328         2.395890           1.851948           3.244656   \n",
       "2      2.466184         2.118250           1.835493           3.169191   \n",
       "3      2.548961         2.187191           1.835670           3.162700   \n",
       "4      2.400417         2.336875           1.747604           3.113589   \n",
       "\n",
       "   t_Xylene (ug/m3)  t_WS (m/s)  t_SR (W/mt2)  t_Volatility_Last_24hr  \\\n",
       "0               0.0    0.314162      3.714195                2.230820   \n",
       "1               0.0    0.330103      3.673794                2.353812   \n",
       "2               0.0    0.329304      3.455326                2.475083   \n",
       "3               0.0    0.326422      3.079282                2.592957   \n",
       "4               0.0    0.379197      2.525195                2.692013   \n",
       "\n",
       "   t_Volatility_Last_7d  t_Volatility_Last_30d  \n",
       "0              4.097861               7.233227  \n",
       "1              4.086369               7.233005  \n",
       "2              4.074597               7.232991  \n",
       "3              4.063127               7.233170  \n",
       "4              4.051925               7.233493  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/generated/all_in_one/Delhi_AQI_final_df_before_modeling.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "df.set_index('Datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the columns that we don't need\n",
    "X_columns = df.drop(['Year', 'y_AQI', 'AQI_Category', 'PM2.5 (ug/m3)', 'PM10 (ug/m3)', 'NO (ug/m3)', 'NO2 (ug/m3)', 'NOx (ug/m3)', 'NH3 (ug/m3)', 'SO2 (ug/m3)', \n",
    "                      'CO (ug/m3)', 'Ozone (ug/m3)', 'Benzene (ug/m3)', 'Toluene (ug/m3)', 'Xylene (ug/m3)', 'WS (m/s)', 'SR (W/mt2)',\n",
    "                      'Volatility_Last_24hr', 'Volatility_Last_7d', 'Volatility_Last_30d'], axis=1).columns.tolist()\n",
    "\n",
    "# Selecting the features (X) and the target variable (y)\n",
    "X = df[X_columns]\n",
    "y = df['y_AQI']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (89784, 31)\n",
      "Shape of y: (89784,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame with a datetime index and the necessary columns\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "split_date = '2022-03-01'\n",
    "\n",
    "# Training set\n",
    "X_train = X[X.index < split_date]\n",
    "y_train = y[y.index < split_date]\n",
    "\n",
    "# Testing set\n",
    "X_test = X[X.index >= split_date]\n",
    "y_test = y[y.index >= split_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasons for Using `reshape(-1, 1)` when Scaling Target Variable\n",
    "\n",
    "- **Scikit-Learn Expectation:** Scikit-learn's scaling functions require a two-dimensional input. `reshape(-1, 1)` ensures the target variable (`y`) is in the expected format.\n",
    "\n",
    "- **Compatibility:** Ensures compatibility with various machine learning libraries, maintaining a consistent data format for both features (`X`) and target variable (`y`).\n",
    "\n",
    "- **Fit-Transform Requirement:** Scikit-learn's `fit_transform` method expects a two-dimensional array. `reshape(-1, 1)` is commonly used to reshape the one-dimensional target variable.\n",
    "\n",
    "- **Consistency in Data Format:** Facilitates consistent data format, promoting clarity and ease of use in machine learning workflows.\n",
    "\n",
    "- **Input Dimension Uniformity:** Guarantees uniform input dimensions for both features and target variable, enhancing the robustness of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the scaler for features and target variable\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the scaler on the training features\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "# Fit and transform the scaler on the training target variable\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "# Transform the test features using the fitted scaler for features\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "# Transform the test target variable using the fitted scaler for the target variable\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure that our X_train_scaled and y_train_scaled are NumPy arrays with appropriate data types.\n",
    "We can check the shapes of X_train_scaled and y_train_scaled to make sure they are compatible with the LSTM input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (80304, 31)\n",
      "<class 'numpy.ndarray'> (80304, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check data types and shapes\n",
    "print(type(X_train_scaled), X_train_scaled.shape)\n",
    "print(type(y_train_scaled), y_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sequences for LSTM\n",
    "Define a function to create sequences of input features and target variable for the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_sequences(data, seq_length):\n",
    "#     X, y = [], []\n",
    "#     for i in range(len(data) - seq_length):\n",
    "#         seq = data[i:i+seq_length]\n",
    "#         label = data[i+seq_length]\n",
    "#         X.append(seq)\n",
    "#         y.append(label)\n",
    "#     return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperparameters and Create Sequences using the function we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_length = 24  # Number of hours to consider for each input sequence\n",
    "\n",
    "# # Create sequences for training data\n",
    "# X_train_seq, y_train_seq = create_sequences(X_train_scaled, seq_length)\n",
    "\n",
    "# # Create sequences for test data\n",
    "# X_test_seq, y_test_seq = create_sequences(X_test_scaled, seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Build the LSTM Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(50, activation='relu', input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model:\n",
    "\n",
    "Let's train our LSTM model using the training sequences (X_train_seq, y_train_seq)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train_seq, y_train_seq, epochs=50, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Test Data:\n",
    "\n",
    "Use the trained model to make predictions on the test sequences (X_test_seq). Inverse transform the scaled predictions to get predictions in the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_scaled = model.predict(X_test_seq)\n",
    "# y_pred = scaler_y.inverse_transform(y_pred_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_test_actual.shape)\n",
    "# print(y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_actual = y_test_actual.reshape(-1)\n",
    "# y_pred = y_pred.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(X_test_seq))\n",
    "# print(len(y_test_seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(y_test_actual))\n",
    "# print(len(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # Inverse transform the scaled actual values for evaluation\n",
    "# y_test_actual = scaler_y.inverse_transform(y_test_seq).reshape(-1)\n",
    "\n",
    "# # Calculate Mean Squared Error (MSE)\n",
    "# mse = mean_squared_error(y_test_actual, y_pred.reshape(-1))\n",
    "# print(f'Mean Squared Error on Test Set: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Predictions:\n",
    "\n",
    "Plot the predicted values against the actual values to visually assess the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(y_test_actual, label='Actual')\n",
    "# plt.plot(y_pred, label='Predicted')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i+seq_length]\n",
    "        label = data[i+seq_length]\n",
    "        X.append(seq)\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose sequence length for the weekly pattern\n",
    "seq_length_weekly = 24 * 7  # weekly pattern\n",
    "\n",
    "# Create sequences for training data\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, seq_length_weekly)\n",
    "\n",
    "# Create sequences for testing data\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, seq_length_weekly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and Compile LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Function to build the LSTM model with Leaky ReLU activation\n",
    "def build_lstm_model(seq_length):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=(seq_length, X_train_seq.shape[2])))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.add(LeakyReLU(alpha=0.1))  # Use Leaky ReLU activation\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.001)  # Custom learning rate\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build and compile the model for the weekly pattern\n",
    "lstm_model_weekly = build_lstm_model(seq_length_weekly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "lstm_model_weekly.fit(X_train_seq, y_train_seq, epochs=20, batch_size=16, validation_split=0.1, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4508/4508 [==============================] - 191s 42ms/step - loss: 0.0563 - val_loss: 0.0579\n",
      "Epoch 2/20\n",
      "4508/4508 [==============================] - 189s 42ms/step - loss: 0.0555 - val_loss: 0.0579\n",
      "Epoch 3/20\n",
      "4508/4508 [==============================] - 191s 42ms/step - loss: 0.0555 - val_loss: 0.0579\n",
      "Epoch 4/20\n",
      "4508/4508 [==============================] - 194s 43ms/step - loss: 0.0555 - val_loss: 0.0579\n",
      "Epoch 5/20\n",
      "4508/4508 [==============================] - 196s 43ms/step - loss: 0.0555 - val_loss: 0.0579\n",
      "Epoch 6/20\n",
      "4508/4508 [==============================] - 198s 44ms/step - loss: 0.0555 - val_loss: 0.0578\n",
      "Epoch 7/20\n",
      "4508/4508 [==============================] - 195s 43ms/step - loss: 0.0555 - val_loss: 0.0578\n",
      "Epoch 8/20\n",
      "4508/4508 [==============================] - 198s 44ms/step - loss: 0.0555 - val_loss: 0.0578\n",
      "Epoch 9/20\n",
      "4508/4508 [==============================] - 201s 45ms/step - loss: 0.0555 - val_loss: 0.0579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a008a910>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "lstm_model_weekly.fit(X_train_seq, y_train_seq, epochs=20, batch_size=16, validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 4s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred_weekly = lstm_model_weekly.predict(X_test_seq)\n",
    "y_test_actual_weekly = scaler_y.inverse_transform(y_test_seq.reshape(-1, 1))\n",
    "y_pred_actual_weekly = scaler_y.inverse_transform(y_pred_weekly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_test_actual_weekly: (288672, 1)\n",
      "Shape of y_pred_actual_weekly: (9312, 1)\n"
     ]
    }
   ],
   "source": [
    "# Ensure shapes before calculating MSE\n",
    "print(\"Shape of y_test_actual_weekly:\", y_test_actual_weekly.shape)\n",
    "print(\"Shape of y_pred_actual_weekly:\", y_pred_actual_weekly.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [288672, 9312]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/braja.bihari/code/misc/AirQualityPredictor/LSTM.ipynb Cell 41\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/braja.bihari/code/misc/AirQualityPredictor/LSTM.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Calculate Mean Squared Error (MSE)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/braja.bihari/code/misc/AirQualityPredictor/LSTM.ipynb#Y102sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mse_weekly \u001b[39m=\u001b[39m mean_squared_error(y_test_actual_weekly, y_pred_actual_weekly)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/braja.bihari/code/misc/AirQualityPredictor/LSTM.ipynb#Y102sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMean Squared Error on Test Set (Weekly Pattern): \u001b[39m\u001b[39m{\u001b[39;00mmse_weekly\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:474\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m    405\u001b[0m     {\n\u001b[1;32m    406\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    416\u001b[0m ):\n\u001b[1;32m    417\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \n\u001b[1;32m    419\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[39m    0.825...\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 474\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[1;32m    475\u001b[0m         y_true, y_pred, multioutput\n\u001b[1;32m    476\u001b[0m     )\n\u001b[1;32m    477\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    478\u001b[0m     output_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage((y_true \u001b[39m-\u001b[39m y_pred) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:99\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     66\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39m        correct keyword.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m    100\u001b[0m     y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    101\u001b[0m     y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    407\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    408\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    412\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [288672, 9312]"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE)\n",
    "mse_weekly = mean_squared_error(y_test_actual_weekly, y_pred_actual_weekly)\n",
    "print(f'Mean Squared Error on Test Set (Weekly Pattern): {mse_weekly}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize actual vs. predicted values\n",
    "plt.plot(y_test_actual_weekly, label='Actual AQI (Weekly Pattern)')\n",
    "plt.plot(y_pred_actual_weekly, label='Predicted AQI (Weekly Pattern)')\n",
    "plt.legend()\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('AQI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 4s 15ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [288672, 9312]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/braja.bihari/code/misc/AirQualityPredictor/LSTM.ipynb Cell 39\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/braja.bihari/code/misc/AirQualityPredictor/LSTM.ipynb#X61sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y_test_actual \u001b[39m=\u001b[39m scaler_y\u001b[39m.\u001b[39minverse_transform(y_test_seq\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/braja.bihari/code/misc/AirQualityPredictor/LSTM.ipynb#X61sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m y_pred_actual \u001b[39m=\u001b[39m scaler_y\u001b[39m.\u001b[39minverse_transform(y_pred)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/braja.bihari/code/misc/AirQualityPredictor/LSTM.ipynb#X61sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m mse \u001b[39m=\u001b[39m mean_squared_error(y_test_actual, y_pred_actual)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/braja.bihari/code/misc/AirQualityPredictor/LSTM.ipynb#X61sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMean Squared Error on Test Set (seq_length=\u001b[39m\u001b[39m{\u001b[39;00mseq_length\u001b[39m}\u001b[39;00m\u001b[39m): \u001b[39m\u001b[39m{\u001b[39;00mmse\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/braja.bihari/code/misc/AirQualityPredictor/LSTM.ipynb#X61sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Visualize actual vs. predicted values\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:474\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m    405\u001b[0m     {\n\u001b[1;32m    406\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    416\u001b[0m ):\n\u001b[1;32m    417\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \n\u001b[1;32m    419\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[39m    0.825...\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 474\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[1;32m    475\u001b[0m         y_true, y_pred, multioutput\n\u001b[1;32m    476\u001b[0m     )\n\u001b[1;32m    477\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    478\u001b[0m     output_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage((y_true \u001b[39m-\u001b[39m y_pred) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:99\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     66\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39m        correct keyword.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m    100\u001b[0m     y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    101\u001b[0m     y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    407\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    408\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    412\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [288672, 9312]"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred = lstm_model_weekly.predict(X_test_seq)\n",
    "y_test_actual = scaler_y.inverse_transform(y_test_seq.reshape(-1, 1))\n",
    "y_pred_actual = scaler_y.inverse_transform(y_pred)\n",
    "\n",
    "mse = mean_squared_error(y_test_actual, y_pred_actual)\n",
    "print(f'Mean Squared Error on Test Set (seq_length={seq_length}): {mse}')\n",
    "\n",
    "# Visualize actual vs. predicted values\n",
    "plt.plot(y_test_actual, label=f'Actual AQI (seq_length={seq_length})')\n",
    "plt.plot(y_pred_actual, label=f'Predicted AQI (seq_length={seq_length})')\n",
    "plt.legend()\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('AQI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80136, 168, 31) (80136, 31)\n",
      "(9312, 168, 31) (9312, 31)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_seq.shape, y_train_seq.shape)\n",
    "print(X_test_seq.shape, y_test_seq.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
